_VERSION = "1.0.0"

"""
Base redis connection for pulling configs/etc.

Allows for single-millisecond retrieval and setting
of data in the main redis memory cache.
"""
import os
import uuid
import json
import time
import redis
import pickle
import boto3
import traceback
import threading

# TODO only initialize connection when used.
class Refinery_Memory:
	json_types = [
		list,
		dict
	]
	
	regular_types = [
		str,
		int,
		float,
		complex,
		bool,
	]
	
	def __init__( self, in_hostname, in_password, namespace ):
		self.redis_client = False
		self.namespace = namespace
		self.hostname = in_hostname
		self.password = in_password
		
	def connect( self ):
		self.redis_client = redis.StrictRedis(
		    host=self.hostname,
		    port=6379,
		    db=0,
		    socket_timeout=2,
		    password=self.password,
		)
		
	def _get_namespace( self, kwargs ):
		if self.namespace == False:
			return ""

		if "raw" in kwargs and kwargs[ "raw" ]:
			return ""
			
		return self.namespace + "."
	
	def set( self, key, input_data, **kwargs ):
		if not self.redis_client:
			self.connect()
		
		namespace = self._get_namespace( kwargs )
			
		if type( input_data ) in self.regular_types:
			self.redis_client.set(
				namespace + key,
				input_data
			)
		elif type( input_data ) in self.json_types:
			self.redis_client.set(
				namespace + key,
				json.dumps(
					input_data
				)
			)
		else:
			self.redis_client.set(
				namespace + key,
				pickle.dumps(
					input_data
				)
			)
			
	def get( self, key, **kwargs ):
		if not self.redis_client:
			self.connect()
			
		namespace = self._get_namespace( kwargs )
		
		data = self.redis_client.get(
			namespace + key
		)
		
		try:
			return json.loads(
				data
			)
		except:
			pass
		
		try:
			return pickle.loads(
				data
			)
		except:
			pass
		
		return data
			
	def exists( self, key, **kwargs ):
		if not self.redis_client:
			self.connect()
			
		namespace = self._get_namespace( kwargs )
		
		return self.redis_client.exists(
			namespace + key
		)
		
	def delete( self, key, **kwargs ):
		if not self.redis_client:
			self.connect()
			
		namespace = self._get_namespace( kwargs )
		
		return self.redis_client.dek(
			namespace + key
		)
		
	def rename( self, key, new_key, **kwargs ):
		if not self.redis_client:
			self.connect()
			
		namespace = self._get_namespace( kwargs )
		
		return self.redis_client.rename(
			namespace + key,
			new_key
		)
		
	def expire_at( self, key, unix_timestamp, **kwargs ):
		if not self.redis_client:
			self.connect()
			
		namespace = self._get_namespace( kwargs )
		
		return self.redis_client.expireat(
			namespace + key,
			unix_timestamp
		)
		
	def expire_in( self, key, seconds, **kwargs ):
		if not self.redis_client:
			self.connect()
			
		namespace = self._get_namespace( kwargs )
		
		return self.redis_client.expire(
			namespace + key,
			seconds
		)
		
	def _get_input_data_from_redis( self, key, **kwargs ):
		if not self.redis_client:
			self.connect()
			
		namespace = self._get_namespace( kwargs )
		pipeline = self.redis_client.pipeline()
		pipeline.get( key )
		pipeline.delete( key )
		returned_data = pipeline.execute()
		
		try:
			return json.loads( returned_data[ 0 ] )
		except:
			pass
		
		return returned_data[ 0 ]
		
	def _store_return_data_to_redis( self, return_data, **kwargs ):
		if not self.redis_client:
			self.connect()
			
		new_key = str( uuid.uuid4() )
			
		self.redis_client.setex(
			new_key,
			( 60 * 5 ),
			json.dumps(
				return_data
			)
		)
		
		return new_key
		
def _parallel_invoke( invoke_queue ):
	# List of active threads
	active_threads = []
	# Maximum number of threads
	max_threads = 10
	
	# Invokes a Lambda asynchronously
	def lambda_invoker_worker( arn, input_data ):
		lambda_client = boto3.client(
			"lambda"
		)
	
		response = lambda_client.invoke(
			FunctionName=arn,
			InvocationType="Event",
			LogType="None",
			Payload=json.dumps(
				input_data
			)
		)
		
		raise SystemExit
	
	# Spawns a new worked and adds it to active_threads
	def spawn_new_worker():
		new_invoke_data = invoke_queue.pop()
		new_thread = threading.Thread(
			target=lambda_invoker_worker,
			args=(
				new_invoke_data[ "arn" ],
				new_invoke_data[ "input_data" ]
			)
		)
		new_thread.start()
		time.sleep(0.05) # Annoying wedge due to boto3 bug
		return new_thread
	
	# Keep looping while there's still Lambdas to invoke
	while len( invoke_queue ) > 0:
		# If we've not maxing out acive threads then spawn new ones
		if len( active_threads ) < max_threads:
			active_threads.append(
				spawn_new_worker()
			)
		else:
			# Iterate over our active threads and remove finished
			new_active_thread_list = []
			already_spawned = False
			# Check if any threads are finished
			for active_thread in active_threads:
				if active_thread.is_alive():
					new_active_thread_list.append( active_thread )
				elif already_spawned == False:
					print( "Refresh!" )
					new_active_thread_list.append(
						spawn_new_worker()
					)
					already_spawned = True
					
			active_threads = new_active_thread_list
			
	# Wait until all threads finish
	for thread in active_threads:
		thread.join()
	
	# We're all done
	return
		
def _call_next( arn, input_data ):
	"""
	Call the next Lambda in the chain.
	"""
	storage_key = gmemory._store_return_data_to_redis( input_data )
	
	return_wrapper_data = {
		"_refinery": {
			"indirect": {
				"type": "redis",
				"key": storage_key,
			}
		}
	}
	
	_lambda_client = boto3.client( "lambda" )
	
	response = _lambda_client.invoke(
	    FunctionName=arn,
	    InvocationType="Event",
	    LogType="None",
	    ClientContext=json.dumps({}),
	    Payload=json.dumps( return_wrapper_data )
	)
	
	return response

def _init( lambda_input, context ):
	# TODO add timer
	
	# Bake in AWS region
	aws_region = "{{AWS_REGION_REPLACE_ME}}"
	
	# Construct log details for debugging
	log_details = {
		"initialization_time": int( time.time() ),
		"aws_region": aws_region,
		"group_name": context.log_group_name,
		"stream_name": context.log_stream_name,
		"function_name": context.function_name,
		"function_version": context.function_version,
		"invoked_function_arn": context.invoked_function_arn,
		"memory_limit_in_mb": context.memory_limit_in_mb,
		"aws_request_id": context.aws_request_id
	}
	
	global cmemory
	global gmemory
	
	cmemory = Refinery_Memory(
		"config-memory.refinery.thehackerblog.com",
		"{{REDIS_PASSWORD_REPLACE_ME}}",
		False
	)
	
	gmemory = Refinery_Memory(
		"global-memory.refinery.thehackerblog.com",
		"{{REDIS_PASSWORD_REPLACE_ME}}",
		context.function_name
	)
	
	# Bake in transition data
	transitions = json.loads( "{{TRANSITION_DATA_REPLACE_ME}}" )
	
	# Detect refinery wrapper and unwrap if existant
	# Else just leave it unmodified
	if "_refinery" in lambda_input:
		_side_loaded = False
		if "indirect" in lambda_input[ "_refinery" ] and "type" in lambda_input[ "_refinery" ][ "indirect" ]:
			# Input data is stored in redis
			if lambda_input[ "_refinery" ][ "indirect" ][ "type" ] == "redis":
				lambda_input = gmemory._get_input_data_from_redis(
					lambda_input[ "_refinery" ][ "indirect" ][ "key" ]
				)
				_side_loaded = True
		
		if not _side_loaded and "input_data" in lambda_input[ "_refinery" ]:
			lambda_input = lambda_input[ "_refinery" ][ "input_data" ]
	
	# Catch any exception that occurs and handle it if a catch is defined.
	try:
		return_data = main( lambda_input, context )
	except:
		exception_string = str( traceback.format_exc() )
		
		if transitions[ "exception" ]:
			_call_next(
				transitions[ "exception" ],
				{
					"version": _VERSION,
					"exception_text": exception_string,
					"input_data": input_data
				}
			)
			return
		else:
			# Nothing to handle it, throw it again.
			raise
	
	# If it's just a then, just invoke the next Lambda
	if transitions[ "then" ]:
		_call_next( transitions[ "then" ], return_data )
		return
		
	# Iterate over every if
	for if_statement_data in transitions[ "if" ]:
		expression_eval_result = eval( if_statement_data[ "expression" ] )
		
		if expression_eval_result:
			result = _call_next( if_statement_data[ "target_arn" ], return_data )
			del result[ "Payload" ]
			return result
		
	# If else is set, call that now
	if transitions[ "else" ]:
		_call_next( transitions[ "else" ], return_data )
		return
	
	return return_data